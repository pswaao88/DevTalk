# ADR-010:컨텍스트-유지-전략-전환

## 상태
Accepted

## 결정 시점
2026-01-19

## 배경
DevTalk의 AI 응답 생성은 현재 `generateContent` 호출 시 매번 대화 로그를 모아 컨텍스트를 구성한다.  
초기는 최근 메시지부터 최대 8000자까지 잘라 전송하는 방식으로 단순하게 구현했다.

그러나 실제 사용 중 다음 문제가 드러났다.

- 대화가 길어질수록 어떤 부분이 잘리는지가 매번 달라져 입력이 흔들린다.
- 같은 질문이어도 컨텍스트 컷팅 결과가 달라 품질이 불안정해질 수 있다.
- 입력이 커질수록 응답이 끊기거나(부분 추출/토큰), UNKNOWN 등 불안정이 증가할 수 있다.
- 벤더 캐시(CachedContent)로 입력 토큰을 줄이는 방향도 고려해보았지만
    - 채팅은 매 턴 컨텍스트가 변한다.
    - CachedContent는 내용 업데이트가 불가하고 재생성 후 ID 교체해야하므로 기존과 다를게 없이 더 복잡하다.

따라서 토큰을 줄이는 벤더 캐시보다, 먼저 입력을 안정화하는 컨텍스트 전략이 우선이라는 결론에 도달했다.

## 결정
벤더 캐시를 사용하지 않고, 컨텍스트 구성 전략을 아래로 전환한다.

- **Prefix 요약 + Tail(최근 N턴) + 최신 질문**
- Prefix 요약은 세션 단위로 저장하며(초기 InMemory), 가끔 갱신한다.
- Tail은 SYSTEM/FAILED 제외, AI 포함, 최근 N개(또는 maxChars)로 제한한다.
- 최신 사용자 입력은 항상 마지막에 명확히 붙여 모델이 “현재 질문”을 정확히 인식하도록 한다.

## 이유
- 입력 구조가 일정해져 응답 품질이 안정화된다.
- 8000자는 상한으로만 사용되고, 실제 입력은 3~5천자 수준으로 유지 가능.
- 구현 복잡도가 낮다(벤더 캐시/TTL/ID 교체/폴백 관리 불필요).
- 기록 우선 원칙에 맞게 실패/시도도 메시지로 유지하면서, 컨텍스트 선택 정책을 명확히 고정할 수 있다.

## 결과
- AiMessageService의 컨텍스트 구성 로직이 변경된다.
- PromptContextBuilder는 최근 8000자 컷의 단일 방식에서, tail 선택을 보조하는 형태로 역할이 축소.
- 세션별 prefix 요약 저장소(SessionMemoryStore) 및 tail 선택기(TailSelector)를 도입한다.
- 요약 갱신은 초기에는 단순 규칙(예: AI 성공 5회마다)으로 트리거만 만들고,
  이후 요약 생성 호출(LLM)로 확장한다.
