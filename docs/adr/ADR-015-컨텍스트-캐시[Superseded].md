# ADR-015: 컨텍스트-스냅샷-캐시-도입

## 상태
Superseded

## 결정 시점
2026-01-19

---

## 배경

초기 구현에서는 AI 응답을 생성할 때마다 다음과 같은 흐름을 사용했다.

- 세션의 전체 메시지 로그 조회
- PromptContextBuilder를 통해 컨텍스트 재구성 (최대 8000자)
- LLM 호출

이 방식은 다음 문제를 야기했다.

1. **중복 비용 문제**
    - 동일한 세션에서 AI 재시도, 토큰 조절 재호출 시
      매번 전체 로그를 조회하고 컨텍스트를 다시 생성해야 했다.
2. **지연 및 불안정성**
    - 컨텍스트 빌드 비용 + 입력 토큰 증가로 응답 지연이 커졌다.
    - 긴 컨텍스트와 높은 maxOutputTokens 설정 시 UNKNOWN 등 내부 실패 확률이 증가했다.

이 문제를 프롬프트 튜닝이나 토큰 증가만으로 해결하는 데에는 한계가 있었다.

---

## 결정

세션 단위로 **컨텍스트 스냅샷(Context Snapshot)** 을 생성하고 캐시하는 구조를 도입한다.

- 컨텍스트 스냅샷은:
    - 메시지 로그를 기반으로
    - LLM 입력용으로 정제된
    - 최대 8000자 이내의 텍스트 결과물이다.
- 스냅샷은 **AI 요청 시마다 생성하지 않는다.**
- 스냅샷은 **대화 상태가 변경되는 시점**에만 갱신한다(ex: 사용자의 입력).

구체적인 정책은 다음과 같다.

1. **캐시 단위**
    - sessionId 기준
2. **갱신시점**
    - USER 메시지 저장 직후
    - AI 메시지 저장 직후
    - SYSTEM 메시지(Resolve/Unresolve) 저장 직후
3. **AI 요청 시**
    - 기존 스냅샷을 그대로 재사용한다.
    - 토큰 재시도, UNKNOWN 재호출 등에서는 스냅샷을 재생성하지 않는다.

---

## 이유
이 결정을 선택한 이유는 다음과 같다.

- **현재 단계에 적합한 단순성**  
  컨텍스트는 “요청 결과”가 아니라 “현재 세션의 대화 상태”를 표현한다.  
  따라서 상태가 변할 때만 갱신하는 캐시 구조가 개념적으로도 맞다.
- **중복 계산 제거**  
  AI 재시도나 토큰 조절로 호출이 여러 번 발생해도  
  컨텍스트 생성은 1회로 제한할 수 있다.
- **안정성과 비용의 균형**  
  컨텍스트 길이를 무작정 늘리는 대신,  
  동일한 컨텍스트를 재사용함으로써 비용과 불안정성을 함께 줄일 수 있다.

의도적으로 포기한 부분은 다음과 같다.

- 실시간으로 완벽한 요약을 만드는 복잡한 로직
- 외부 캐시(Redis 등)를 바로 도입하는 것  
  → 초기에는 InMemory 캐시로 단순하게 시작한다.

---

## 결과
- AI 호출 로직에서 전체 히스토리 조회 및 컨텍스트 빌드가 제거된다.
- 컨텍스트 생성 및 캐시 관리는 `ContextSnapshotService`가 전담한다.
- 메시지 로그(Message)는 원본 그대로 유지되고,
  컨텍스트 스냅샷은 파생 데이터이자 캐시 대상으로 취급된다.
- AI 재시도나 토큰 조절 시에도 컨텍스트는 안정적으로 유지된다.
