# ADR-018: DevTalk-응답-실시간-렌더링

## 상태
Accepted

## 결정 시점
2026-01-20

## 배경

DevTalk의 AI 응답 생성은
- 요약
- 최근 대화
- 최신 질문

을 조합한 뒤 LLM을 호출하는 구조다.

컨텍스트 안정화 이후 응답 품질은 개선되었지만,
응답 생성 시간이 길어질수록
사용자는 빈 화면을 보며 대기해야 했다.

이는 대화형 서비스로서 치명적인 UX 문제이다.

---

## 결정

AI 응답을 한 번에 반환하는 방식 대신,
**LLM 스트리밍 응답을 서버에서 중계하여
프론트에서 실시간으로 렌더링**하는 방식을 채택한다.

구조는 다음과 같다.

- 프론트 ↔ 서버: Server-Sent Events(SSE)
- 서버 ↔ LLM: 스트리밍 API

응답 완료 시점에만
AI 메시지를 최종 저장한다.

---

## 이유

- 사용자는 응답 생성 진행 상황을 즉시 확인할 수 있다.
- 응답 지연에 대한 체감이 크게 감소한다.
- DevTalk의 컨텍스트/요약/실패 기록 구조를 그대로 유지할 수 있다.
- LLM을 직접 노출하지 않고 서버가 모든 상태를 통제할 수 있다.

---

## 결과

- AI 응답 생성 UX가 웹 채팅 AI 수준으로 개선된다.
- 응답 실패, 중단, 지연 상황도 실시간으로 사용자에게 전달 가능하다.
- 저장 로직과 렌더링 로직이 명확히 분리된다.
